{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e06c9e4-013a-47f4-97ff-5092cf155789",
   "metadata": {},
   "source": [
    "ASSIGNMENT: STATISTICS-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfed2012-6853-4c8c-9231-53684f733f12",
   "metadata": {},
   "source": [
    "1. What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with \n",
    "an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10035dab-24e5-4607-b11d-c1837a5da9fc",
   "metadata": {},
   "source": [
    "The Probability Mass Function (PMF) and Probability Density Function (PDF) are two important concepts in probability theory used to describe the probability distribution of a random variable.\n",
    "\n",
    "A probability mass function (PMF) is a function that maps each possible value of a discrete random variable to the probability of that value occurring. In other words, it gives the probability that a discrete random variable X takes on a specific value. The PMF is denoted by P(X = x).\n",
    "\n",
    "For example, consider a fair six-sided dice. The PMF of this dice would be:\n",
    "\n",
    "P(X=1) = P(X=2) = P(X=3) = P(X=4) = P(X=5) = P(X=6) = 1/6\n",
    "\n",
    "This means that the probability of rolling a 1, 2, 3, 4, 5, or 6 on this dice is 1/6 each.\n",
    "\n",
    "On the other hand, a probability density function (PDF) is a function that describes the probability distribution of a continuous random variable. Unlike the PMF, which deals with discrete random variables, the PDF deals with continuous random variables. The PDF is defined as the derivative of the cumulative distribution function (CDF). The PDF is denoted by f(X).\n",
    "\n",
    "For example, let's consider the normal distribution, which is a continuous probability distribution widely used in statistics. The PDF of the normal distribution is given by:\n",
    "\n",
    "f(x) = (1/(σ√2π)) * e^(-(x-μ)^2/(2σ^2))\n",
    "\n",
    "where μ is the mean of the distribution, σ is the standard deviation, and e is the base of the natural logarithm.\n",
    "\n",
    "The PDF describes the shape of the probability distribution of the normal distribution. It shows that the probability is highest at the mean and decreases as we move away from the mean in either direction. The area under the PDF curve gives the total probability of the random variable taking any value in the given range.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ac4067-0ac3-42a7-93fa-097bff173435",
   "metadata": {},
   "source": [
    "2. What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff31d94-0f9e-4b13-b012-cb31927b4237",
   "metadata": {},
   "source": [
    "The Cumulative Density Function (CDF) is a function that describes the probability of a random variable X taking a value less than or equal to a specific value x. It is denoted as F(X=x).\n",
    "\n",
    "In other words, the CDF gives the probability that a random variable X is less than or equal to a specific value x. The CDF is defined for both discrete and continuous random variables.\n",
    "\n",
    "For example, let's consider a coin flip experiment. The CDF for this experiment would be:\n",
    "\n",
    "F(X=0) = 0.5 (since the probability of getting tails is 0.5)\n",
    "F(X=1) = 1 (since the probability of getting heads is 0.5 and the probability of getting tails is 0.5, the cumulative probability of getting either heads or tails is 1)\n",
    "\n",
    "The CDF of a continuous random variable can be graphed as a smooth curve. For example, the CDF of the normal distribution can be graphed as a bell-shaped curve.\n",
    "\n",
    "The CDF is used in probability theory to describe the cumulative probability distribution of a random variable. It is useful for calculating the probability that a random variable falls within a specific range or interval. It can also be used to find percentiles of a distribution, which represent the point below which a given percentage of observations fall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5c9314-5e83-400f-8d7c-970212c43b27",
   "metadata": {},
   "source": [
    "3. What are some examples of situations where the normal distribution might be used as a model? \n",
    "Explain how the parameters of the normal distribution relate to the shape of the distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a4bdae-9c31-4e1e-8ead-7128d28e5833",
   "metadata": {},
   "source": [
    "The normal distribution, also known as the Gaussian distribution, is a continuous probability distribution widely used in statistics to model many real-world phenomena. Some examples of situations where the normal distribution might be used as a model are:\n",
    "\n",
    "Heights of adult humans: The heights of adult humans generally follow a normal distribution, with the mean height and standard deviation varying based on factors such as age, gender, and ethnicity.\n",
    "\n",
    "IQ scores: IQ scores are often modeled using a normal distribution with a mean of 100 and a standard deviation of 15.\n",
    "\n",
    "Errors in measurements: The errors in measurements in fields such as engineering and physics are often assumed to follow a normal distribution.\n",
    "\n",
    "The normal distribution is characterized by two parameters: the mean (μ) and the standard deviation (σ). The mean is the center of the distribution, and the standard deviation measures the spread or variability of the distribution. The larger the value of the standard deviation, the more spread out the distribution is.\n",
    "\n",
    "The shape of the normal distribution depends on the values of the mean and standard deviation. Specifically, the shape of the normal distribution is symmetric and bell-shaped, with the highest point at the mean. The standard deviation determines the spread of the curve, with a larger standard deviation resulting in a flatter curve with a lower peak, and a smaller standard deviation resulting in a narrower curve with a higher peak.\n",
    "\n",
    "Moreover, the Empirical Rule or 68-95-99.7 rule applies to normal distribution which states that approximately 68% of the data falls within one standard deviation from the mean, 95% falls within two standard deviations, and 99.7% falls within three standard deviations from the mean. This makes the normal distribution an extremely useful tool in statistics and data analysi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594647c1-8b94-4f2c-b8b6-2ab6923e955e",
   "metadata": {},
   "source": [
    "4. Explain the importance of Normal Distribution. Give a few real-life examples of Normal \n",
    "Distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201f354a-bad9-46de-89b3-a6de062bce61",
   "metadata": {},
   "source": [
    "The normal distribution, also known as the Gaussian distribution, is one of the most important probability distributions in statistics. It is used to model a wide variety of real-world phenomena and is an essential tool for statistical analysis. Here are some reasons why the normal distribution is important:\n",
    "\n",
    "Central Limit Theorem: The normal distribution plays a key role in the Central Limit Theorem, which states that the sum or average of a large number of independent and identically distributed random variables will be approximately normally distributed, regardless of the distribution of the individual variables. This theorem is fundamental to many statistical methods.\n",
    "\n",
    "Inferential Statistics: Many inferential statistics, such as hypothesis testing and confidence intervals, rely on the normal distribution. This is because many real-world phenomena are approximately normally distributed, and the normal distribution provides a useful framework for making statistical inferences.\n",
    "\n",
    "Probability: The normal distribution is a continuous probability distribution, which makes it useful for calculating probabilities of continuous events. It is often used in risk management and financial modeling to estimate the probability of different outcomes.\n",
    "\n",
    "Some real-life examples of normal distribution are:\n",
    "\n",
    "Heights of adult humans: The heights of adult humans generally follow a normal distribution, with the mean height and standard deviation varying based on factors such as age, gender, and ethnicity.\n",
    "\n",
    "Exam scores: In a large population, the distribution of exam scores tends to follow a normal distribution. This makes it possible to calculate percentiles and compare the performance of different students.\n",
    "\n",
    "Monthly rainfall: In many regions, monthly rainfall amounts follow a normal distribution. This is important for agriculture and water resource management.\n",
    "\n",
    "Body temperature: The body temperature of healthy adults is normally distributed around a mean of 98.6 degrees Fahrenheit (37 degrees Celsius).\n",
    "\n",
    "IQ scores: IQ scores are often modeled using a normal distribution with a mean of 100 and a standard deviation of 15."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70367cc-bb77-49c0-aea2-8603831869ed",
   "metadata": {},
   "source": [
    "5. What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli \n",
    "Distribution and Binomial Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8231c74-b411-455a-b18e-3e6ecf64a541",
   "metadata": {},
   "source": [
    "he Bernoulli distribution is a discrete probability distribution that describes a single binary event with two possible outcomes, usually labeled as success (represented by 1) or failure (represented by 0). The Bernoulli distribution is named after the Swiss mathematician Jacob Bernoulli.\n",
    "\n",
    "The probability mass function (PMF) of a Bernoulli distribution with parameter p is given by:\n",
    "\n",
    "P(X = x) = p^x(1-p)^(1-x) for x = 0,1\n",
    "\n",
    "Where X is a random variable that takes on the values 0 or 1, and p is the probability of success.\n",
    "\n",
    "An example of the Bernoulli distribution is the flip of a coin, where success represents getting heads and failure represents getting tails. If we assume that the coin is fair, then the probability of success (getting heads) is p=0.5, and the probability of failure (getting tails) is 1-p=0.5. Thus, the Bernoulli distribution with parameter p=0.5 represents the probability of getting heads or tails on a single flip of a fair coin.\n",
    "\n",
    "The main difference between the Bernoulli distribution and the binomial distribution is that the Bernoulli distribution describes a single binary event, while the binomial distribution describes the number of successes in a fixed number of independent Bernoulli trials. In other words, the Bernoulli distribution is a special case of the binomial distribution, where n=1.\n",
    "\n",
    "The binomial distribution is given by the PMF:\n",
    "\n",
    "P(X = k) = (n choose k) p^k (1-p)^(n-k) for k = 0,1,2,...,n\n",
    "\n",
    "Where X is the number of successes in n independent Bernoulli trials, p is the probability of success on each trial, and (n choose k) is the binomial coefficient, which represents the number of ways to choose k successes out of n trials.\n",
    "\n",
    "For example, if we flip a fair coin 10 times and count the number of heads, the number of heads is a binomial random variable with parameters n=10 and p=0.5. The probability of getting exactly k heads (successes) out of 10 flips is given by the binomial distribution with these parameters.\n",
    "\n",
    "In summary, the Bernoulli distribution describes a single binary event, while the binomial distribution describes the number of successes in a fixed number of independent Bernoulli trials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6500b6b1-3a88-49f2-ac64-0fbef7d060d6",
   "metadata": {},
   "source": [
    "6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset \n",
    "is normally distributed, what is the probability that a randomly selected observation will be greater \n",
    "than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db763012-93df-4b8e-b61c-210cfb1fd8d8",
   "metadata": {},
   "source": [
    "We can use the standard normal distribution to answer this question by transforming the given data to have a mean of 0 and a standard deviation of 1. This is done by subtracting the mean (50) from the value of interest (60) and dividing by the standard deviation (10), giving:\n",
    "\n",
    "z = (60 - 50) / 10 = 1\n",
    "\n",
    "We can then use the standard normal distribution table or a calculator to find the probability that a randomly selected observation will be greater than 60. The area to the right of z=1 under the standard normal curve represents this probability.\n",
    "\n",
    "Using a standard normal distribution table or a calculator, we can find that the area to the right of z=1 is approximately 0.1587.\n",
    "\n",
    "Therefore, the probability that a randomly selected observation from the given dataset will be greater than 60 is approximately 0.1587.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418129e9-aa31-4727-a512-8bda9dce3b74",
   "metadata": {},
   "source": [
    "7. Explain uniform Distribution with an example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3c6a90-7396-4cca-803b-e44b17157ec5",
   "metadata": {},
   "source": [
    "The uniform distribution is a continuous probability distribution that assigns equal probability to all possible outcomes within a given range. This means that each value within the range is equally likely to occur. The uniform distribution is often used when there is no a priori reason to believe that one value is more likely than any other value within the range.\n",
    "\n",
    "The probability density function (PDF) of a uniform distribution over the interval [a,b] is given by:\n",
    "\n",
    "f(x) = 1/(b-a) for a ≤ x ≤ b\n",
    "0 otherwise\n",
    "\n",
    "where f(x) represents the probability density at a given value x.\n",
    "\n",
    "An example of the uniform distribution is the roll of a fair six-sided die. Since each face of the die is equally likely to come up, the probability of rolling any particular number (1, 2, 3, 4, 5, or 6) is 1/6. This can be modeled using the uniform distribution over the interval [1,6], where a=1 and b=6.\n",
    "\n",
    "Another example is the distribution of birth dates in a population, assuming that each day of the year is equally likely for a birth to occur. This can be modeled using the uniform distribution over the interval [1,365], where a=1 represents January 1st and b=365 represents December 31st.\n",
    "\n",
    "In general, the uniform distribution is used in situations where all outcomes within a given range are equally likely, and there is no reason to believe that one outcome is more likely than any other outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4899e020-1ae6-4a8c-8115-ece4b086b19b",
   "metadata": {},
   "source": [
    "8. What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afc8593-d384-412f-bce5-3cd71d66d7b6",
   "metadata": {},
   "source": [
    "The z-score, also known as the standard score, is a statistical measure that expresses the distance between an observation and the mean of a population or sample in terms of standard deviations. It indicates how many standard deviations an observation is above or below the mean of the population or sample.\n",
    "\n",
    "The formula for calculating the z-score of an observation x, given a population mean μ and a population standard deviation σ, is:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "The z-score is important because it standardizes data and allows us to compare observations from different populations or samples that have different scales and units. By converting data to z-scores, we can easily calculate the proportion of observations that fall above or below a certain threshold, regardless of the original units of measurement.\n",
    "\n",
    "Z-scores are also used to identify outliers or extreme values in a dataset. Observations with z-scores greater than 3 or less than -3 are typically considered to be outliers, as they are more than three standard deviations away from the mean.\n",
    "\n",
    "Finally, the z-score is used to calculate the probability of obtaining a given observation or a more extreme observation, assuming that the data follows a normal distribution. This is done by looking up the corresponding probability in a standard normal distribution table or by using statistical software.\n",
    "\n",
    "In summary, the z-score is an important statistical measure that standardizes data, facilitates comparisons between different populations or samples, identifies outliers, and allows us to calculate probabilities assuming a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482d04ff-9c92-4e40-8b37-6fe31275d2df",
   "metadata": {},
   "source": [
    "9. What is Central Limit Theorem? State the significance of the Central Limit Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26ddb23-c9c3-4687-923b-b6d3bceaebc2",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a fundamental result in statistics that states that the distribution of sample means of sufficiently large sample sizes, taken from any population, will be approximately normally distributed, regardless of the underlying distribution of the population from which the samples were taken. Specifically, the CLT states that as the sample size increases, the sampling distribution of the mean approaches a normal distribution, with a mean equal to the population mean and a standard deviation equal to the population standard deviation divided by the square root of the sample size.\n",
    "\n",
    "The significance of the CLT lies in the fact that it allows us to make probabilistic statements about the mean of a population, based on a sample mean. This is important because it allows us to estimate the parameters of a population, even when we cannot observe or measure every individual in the population. For example, if we want to estimate the average height of all people in a city, we can take a random sample of people and calculate the sample mean. The CLT tells us that if our sample size is large enough, the distribution of sample means will be approximately normal, which allows us to estimate the population mean and calculate the probability of observing a sample mean within a certain range of values.\n",
    "\n",
    "The CLT also has important practical applications in fields such as quality control, finance, and engineering, where it is often necessary to estimate population parameters based on sample data. By allowing us to make probabilistic statements about population parameters, the CLT enables us to make more informed decisions and reduce the risk of errors or failures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef44823-1412-456a-b95f-560803d56d0f",
   "metadata": {},
   "source": [
    "10. State the assumptions of the Central Limit Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340694c2-e856-4404-aa17-0028bd713e88",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a fundamental theorem in probability theory, which describes the behavior of the sample means for large sample sizes. The assumptions of the Central Limit Theorem are:\n",
    "\n",
    "Independence: The observations in the sample are independent of each other.\n",
    "\n",
    "Random Sampling: The sample is drawn randomly from the population of interest.\n",
    "\n",
    "Finite Variance: The population from which the sample is drawn has a finite variance.\n",
    "\n",
    "Identical Distribution: Each observation in the sample is drawn from the same probability distribution.\n",
    "\n",
    "Under these assumptions, the Central Limit Theorem states that the sample mean of a sufficiently large sample size (typically at least 30) will be approximately normally distributed, regardless of the distribution of the population from which the sample was drawn. The mean of the sample means will be equal to the population mean, and the standard deviation of the sample means will be equal to the population standard deviation divided by the square root of the sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b077fac-5715-47aa-87f1-c4bc9f221462",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
